
# Using Postgres üíΩ

> [!note]
> The minimum supported version of PostgreSQL is determined by the Dependency Deprecation Policy.

## Install postgres client libraries

Synapse will require the python **postgres** client library in order to connect to a postgres database.

- If you are using the matrix.org debian/ubuntu packages, the necessary python library will already be installed, but you will need to ensure the low-level postgres library is installed, which you can do with apt install libpq5.

- For other pre-built packages, please consult the documentation from the relevant package.

- If you installed synapse in a virtualenv, you can install the library with: `~/synapse/env/bin/pip install "matrix-synapse[postgres]"`

> [!note]
> (substituting the path to your virtualenv for ~/synapse/env, if you used a different path). You will require the postgres development files. These are in the libpq-dev package on Debian-derived distributions.

## Set up database

Assuming your PostgreSQL database user is called postgres, first authenticate as the database user with:

```bash
su - postgres
# Or, if your system uses sudo to get administrative rights
sudo -u postgres bash
```

Then, create a postgres user and a database with:

```bash
createdb --encoding=UTF8 --locale=C --template=template0 --owner=homelab synapse
```

The above will create a user called synapse_user, and a database called synapse.

Note that the PostgreSQL database must have the correct encoding set (as shown above), otherwise it will not be able to store UTF8 strings.

You may need to enable password authentication so synapse_user can connect to the database. See https://www.postgresql.org/docs/current/auth-pg-hba-conf.html.
Synapse config

When you are ready to start using PostgreSQL, edit the database section in your config file to match the following lines:

```yaml
database:
  name: psycopg2
  args:
    user: <user>
    password: <pass>
    dbname: <db>
    host: <host>
    cp_min: 5
    cp_max: 10

```

> [!warning]
> All key, values in args are passed to the psycopg2.connect(..) function, except keys beginning with cp_, which are consumed by the twisted adbapi connection pool. See the libpq documentation for a list of options which can be passed.

You should consider tuning the args.keepalives_* options if there is any danger of the connection between your homeserver and database dropping, otherwise Synapse may block for an extended period while it waits for a response from the database server. 

Example values might be:

```yaml
database:
  args:
    # ... as above

    # seconds of inactivity after which TCP should send a keepalive message to the server
    keepalives_idle: 10

    # the number of seconds after which a TCP keepalive message that is not
    # acknowledged by the server should be retransmitted
    keepalives_interval: 10

    # the number of TCP keepalives that can be lost before the client's connection
    # to the server is considered dead
    keepalives_count: 3
```

## Allowing Postgresql to receive docker connections (if on host)

```bash
FATAL:  no pg_hba.conf entry for host "172.27.0.2", user "homelab", database "matrix-chat", no encryption
```

Means your `pg_hba.conf` **does not allow unencrypted connections** from Docker subnets like `172.27.0.2`. To fix this:

### ‚úÖ Solution: Add a permissive pg_hba.conf rule for all Docker containers

Edit your `pg_hba.conf` file and add this line **above** other `host` entries:

```bash
hostnossl   all             all             172.16.0.0/12            md5
```

### ‚úèÔ∏è Why this works?

- `hostnossl`: allows TCP connections **without SSL** (Docker containers usually don't use SSL for localhost-style DB access).
    
- `all`: allow any database.
    
- `all`: allow any user.
    
- `172.16.0.0/12`: this **covers all Docker networks** (`172.16.0.0 ‚Äì 172.31.255.255`).
    
- `md5`: use password authentication.

### üöÄ Steps to Apply

1. Edit `pg_hba.conf` (e.g., `sudo nano /var/lib/postgres/data/pg_hba.conf`).
    
2. Add this line at the top of all `host` entries:
   
```bash
`hostnossl all all 172.16.0.0/12 md5`
```

3. üîß **Fix**:
Edit `postgresql.conf` (usually found in `/var/lib/postgres/data/`, `/etc/postgresql/<version>/main/`, or inside your Docker volume).

Look for:

```conf
listen_addresses = 'localhost'
```

And change it to:

```conf
listen_addresses = '*'
```

4.  Restart PostgreSQL or reload config:

```bash
sudo systemctl reload postgresql
```

## Backups

Don't forget to back up your database!

## Tuning Postgres

The default settings should be fine for most deployments. For larger scale deployments tuning some of the settings is recommended, details of which can be found at https://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server.

In particular, we've found tuning the following values helpful for performance:

    shared_buffers
    effective_cache_size
    work_mem
    maintenance_work_mem
    autovacuum_work_mem

Note that the appropriate values for those fields depend on the amount of free memory the database host has available.

Additionally, admins of large deployments might want to consider using huge pages to help manage memory, especially when using large values of shared_buffers. You can read more about that here.
Porting from SQLite
Overview

The script synapse_port_db allows porting an existing synapse server backed by SQLite to using PostgreSQL. This is done as a two phase process:

    Copy the existing SQLite database to a separate location and run the port script against that offline database.
    Shut down the server. Rerun the port script to port any data that has come in since taking the first snapshot. Restart server against the PostgreSQL database.

The port script is designed to be run repeatedly against newer snapshots of the SQLite database file. This makes it safe to repeat step 1 if there was a delay between taking the previous snapshot and being ready to do step 2.

It is safe to at any time kill the port script and restart it.

However, under no circumstances should the SQLite database be VACUUMed between multiple runs of the script. Doing so can lead to an inconsistent copy of your database into Postgres. To avoid accidental error, the script will check that SQLite's auto_vacuum mechanism is disabled, but the script is not able to protect against a manual VACUUM operation performed either by the administrator or by any automated task that the administrator may have configured.

Note that the database may take up significantly more (25% - 100% more) space on disk after porting to Postgres.
Using the port script

Firstly, shut down the currently running synapse server and copy its database file (typically homeserver.db) to another location. Once the copy is complete, restart synapse. For instance:

```bash
synctl stop
cp homeserver.db homeserver.db.snapshot
synctl start
```

Copy the old config file into a new config file:

```bash
cp homeserver.yaml homeserver-postgres.yaml
```

Edit the database section as described in the section Synapse config above and with the SQLite snapshot located at homeserver.db.snapshot simply run:

```bash
synapse_port_db --sqlite-database homeserver.db.snapshot \
    --postgres-config homeserver-postgres.yaml
```

The flag --curses displays a coloured curses progress UI. (NOTE: if your terminal is too small the script will error out)

If the script took a long time to complete, or time has otherwise passed since the original snapshot was taken, repeat the previous steps with a newer snapshot.

To complete the conversion shut down the synapse server and run the port script one last time, e.g. if the SQLite database is at homeserver.db run:

```bash
synapse_port_db --sqlite-database homeserver.db \
    --postgres-config homeserver-postgres.yaml
```

Once that has completed, change the synapse config to point at the PostgreSQL database configuration file homeserver-postgres.yaml:

```bash
synctl stop
mv homeserver.yaml homeserver-old-sqlite.yaml
mv homeserver-postgres.yaml homeserver.yaml
synctl start
```

Synapse should now be running against PostgreSQL.

# Troubleshooting

## Alternative auth methods

If you get an error along the lines of FATAL: Ident authentication failed for user "synapse_user", you may need to use an authentication method other than ident:

If the synapse_user user has a password, add the password to the database: section of homeserver.yaml. Then add the following to pg_hba.conf:

```.conf
host    synapse     synapse_user    ::1/128     md5  # or `scram-sha-256` instead of `md5` if you use that
```

If the synapse_user user does not have a password, then a password doesn't have to be added to homeserver.yaml. But the following does need to be added to pg_hba.conf:

```conf
host    synapse     synapse_user    ::1/128     trust

# Note that line order matters in pg_hba.conf, so make sure that if you do add a # new line, it is inserted before:

host    all         all             ::1/128     ident
```

## Fixing incorrect COLLATE or CTYPE

Synapse will refuse to start when using a database with incorrect values of ***COLLATE*** and ***CTYPE*** unless the config flag allow_unsafe_locale, found in the database section of the config, is set to true. Using different locales can cause issues if the locale library is updated from underneath the database, or if a different version of the locale is used on any replicas.

If you have a database with an unsafe locale, the safest way to fix the issue is to dump the database and recreate it with the correct locale parameter (as shown above). It is also possible to change the parameters on a live database and run a ***REINDEX*** on the entire database, however extreme care must be taken to avoid database corruption.

Note that the above may fail with an error about duplicate rows if corruption has already occurred, and such duplicate rows will need to be manually removed.
## Permissions 

Seems that's necessary to grant permissions to `$UID` and `$GUID` equals your user on the data directories.

```bash
sudo chown -R vv:vv ~/.hosted/matrix-chat/data
``` 

## Homeserver.log

This is an strange one. I needed to create a `*.log.config` file within the mounted volume for `/data/...` having the public domain name preceding it. `alexvergara.duckdns.org.log.config` with the following content:

```txt
‚îå‚îÄ> Ôåí  vv at Ó¨Å vv-minipc in @192.168.10.95 ~ took 16m22s
‚ú¶ ‚ùØ sudo cat .hosted/matrix-chat/data/synapse/alexvergara.duckdns.org.log.config
[sudo] password for vv:
version: 1

formatters:
  precise:

    format: '%(asctime)s - %(name)s - %(lineno)d - %(levelname)s - %(request)s - %(message)s'


handlers:
  console:
    class: logging.StreamHandler
    formatter: precise

loggers:
    synapse.storage.SQL:
        # beware: increasing this to DEBUG will make synapse log sensitive
        # information such as access tokens.
        level: INFO

root:
    level: INFO


    handlers: [console]


disable_existing_loggers: false
```

## /app/config.json on element

Maybe we messed up all the permissions without considering some of them. For example, `matrix-element` needs write permissions on the host content of the mounted volume for `/app`. Easy fix tho!

```bash
chmod 644 .hosted/matrix-chat/data/element/config.json
```

And now just restart everything:

```bash
docker-compose -f ~/.hosted/matrix-chat/docker-compose.yaml down && docker-compose -f ~/.hosted/matrix-chat/docker-compose.yaml up -d
```

# OIDC with Authelia

Configuration is already written on the configuration files. But here's the common troubleshooting

## 1. Set the Proper Permissions on Your CA Certificate

Make sure the CA file is world‚Äëreadable so Docker can access it:

```bash
chmod 644 ~/.hosted/certs/home.lab.crt
```

## 2. Copy the CA Certificate into the Synapse Container

Copy the CA certificate into the folder where update-ca-certificates looks for extra certificates. We‚Äôll use `/usr/local/share/ca-certificates/` as the target:

```bash
docker cp ~/.hosted/certs/home.lab.crt matrix-synapse:/usr/local/share/ca-certificates/home.lab.crt
```

> [!Note]
> You can change the target filename (here ‚Äúhome.lab.crt‚Äù) if you prefer, as long as it ends with ‚Äú.crt‚Äù.

## 3. Update the Container‚Äôs Certificate Store

Run the update-ca-certificates command inside the container so that the new file is processed and added to the trust store:

```bash
docker exec -it matrix-synapse update-ca-certificates
```

You should see output like ‚Äú1 added‚Äù (ignore warnings about other files such as ca-certificates.crt if they already exist).
## 4. Test the Connection from Within the Container

Now try retrieving the OIDC discovery document without using the --insecure flag:

```bash
docker exec -it matrix-synapse curl -v https://auth.home.lab/.well-known/openid-configuration
```

If the certificate is correctly installed, curl should no longer complain about an unknown CA and you should see a proper HTTP/2 200 response with the JSON payload.

## 5. (Optional) Persist the CA Certificate via Docker Compose

If you prefer the certificate to be mounted automatically each time Synapse starts, you can add a volume to your docker-compose file under the synapse service. Edit your ~/.hosted/matrix-chat/docker-compose.yaml and add:

```yaml
  synapse:
    image: matrixdotorg/synapse:latest
    container_name: matrix-synapse
    ...
    volumes:
      - ~/.hosted/matrix-chat/data/synapse:/data
      - ~/.hosted/certs/home.lab.crt:/usr/local/share/ca-certificates/home.lab.crt:ro
```

*Then restart the container*

## Final Notes

- **Verify the Certificate:**  
    Double-check that the file at ~/.hosted/certs/home.lab.crt is the correct CA certificate (i.e. it should be the root certificate that signed your Authelia certificate). If it isn‚Äôt, you‚Äôll need the proper CA certificate instead.
    
- **Self‚ÄëSigned Certificate Warning:**  
    Even after installing the CA certificate, be mindful that using self‚Äësigned certificates (or internal CAs) can open up risks if not carefully managed. For production, using certificates from a public CA (or Let's Encrypt) is generally preferred.

These commands should allow you to get Synapse to trust your internal OIDC endpoint.